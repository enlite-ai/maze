# @package algorithm

# Number of epochs to train for
n_epochs: 1000

# Optimizer used to update the policy
optimizer:
  _target_: torch.optim.Adam
  lr: 0.001

# Device to train on
device: cuda

# Batch size
batch_size: 100

# Number of iterations after which to run evaluation (in addition to evaluations at the end of
# each epoch, which are run automatically). If set to None, evaluations will run on epoch end only.
eval_every_k_iterations: 500

# Percentage of the data used for validation.
validation_percentage: 20

# Number of episodes to run during each evaluation rollout (set to 0 to evaluate using validation only)
n_eval_episodes: 8

# Entropy coefficient for policy optimization.
entropy_coef: 0.0

# The loss to be used for the behavioural cloning.
loss:
  _target_: maze.train.trainers.imitation.bc_loss.BCLoss
