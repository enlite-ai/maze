# Default configuration for policy training.

defaults:
  - runner: local
  - env: gym_env
  - wrappers: no_wrappers
  - algorithm: es
  - model: flatten_concat
  - critic: ~
  - launcher: ~
  - configuration: ~

  # Algorithm runner specialization
  - algorithm_runner: ${algorithm}-${runner}

  # Launcher specializations for Kubernetes runs
  - optional algorithm_launcher: ${algorithm}-${launcher}
  - optional runner_launcher: ${runner}-${launcher}

  # Configuration specializations (mainly for test scenarios, to keep tests simple and fast)
  - optional env_configuration: ${env}-${configuration}
  - optional algorithm_configuration: ${algorithm}-${configuration}

project:
  name: ???

# --- Hydra output directory specifications ---

# Base directory where to output logs
log_base_dir: outputs

# Hydra is by default configured to create a fresh output directory for each run.
# However, to ensure model states, normalization stats and else are loaded from expected
# locations, we will change the dir back to the original working dir for the initialization
# (and then change it back so that all later script output lands in the hydra output dir as expected)
input_dir: ""

# Maze seeding. If no seeds are given they are generated and the seeds used are documented in
# the hydra_config.yaml file in order to reproduce experiments.
seeding:
  # Base seed for creating env seeds
  env_base_seed: ~
  # Base seed for creating agent seeds
  agent_base_seed: ~
  # Specify whether to set the cudnn determinism flag, this will ensure guaranty when working on the gpu, however some
  # torch modules will raise runtime errors, and the processing speed will be decreased.
  cudnn_determinism_flag: false

# Configuration for Hydra
hydra:
  # Local trainings
  run:
    # note that the directory name is based on microseconds (%f) to make it extremely unlikely that simultaneously
    # started runs do not accidentally write to the same output directory
    dir: ${log_base_dir}/${hydra:runtime.choices.env}-${hydra:runtime.choices.model}-${hydra:runtime.choices.algorithm}-${hydra:runtime.choices.runner}/${now:%Y-%m-%d_%H-%M-%f}
  # Training launched through launchers (i.e. kubernetes-based)
  sweep:
    dir: ${log_base_dir}/sweep/${now:%Y-%m-%d_%H-%M-%f}
